[{"id":0,"href":"/SCA/docs/gin-gonic_gin/0001_preface/","title":"0001 Preface","section":"gin-gonic/gin","content":"源码解析之:gin #  gin 是一个用golang实现的HTTPweb框架。\n特性 #  官网上描述，gin的特性包括：\n 快：路由使用基数树，低内存，不使用反射； 中间件注册：一个请求可以被一系列的中间件和最后的action处理 奔溃处理：gin可以捕获panic使应用程序可用 JSON校验：将请求的数据转换为JSON并校验 路由组：更好的组织路由的方式，无限制嵌套而不影响性能 错误管理：可以收集所有的错误 内建渲染方式：JSON，XML和HTML渲染方式 可继承：简单的去创建中间件  代码结构 #  |-- binding 将请求的数据对象化并校验 |-- examples 各种列子 |-- json 提供了另外一种json实现 |-- render 响应 |-- gin.go gin引擎所在 |-- gin_test.go |-- routes_test.go |-- context.go 上下文，将各种功能聚焦到上下文（装饰器模式） |-- context_test.go |-- response_writer.go 响应的数据输出 |-- response_writer_test.go |-- errors.go 错误处理 |-- errors_test.go |-- tree.go 路由的具体实现 |-- tree_test.go |-- routergroup.go |-- routergroup_test.go |-- auth.go 一个基本的HTTP鉴权的中间件 |-- auth_test.go |-- logger.go 一个日志中间件 |-- logger_test.go |-- recovery.go 一个崩溃处理插件 |-- recovery_test.go |-- mode.go 应用模式 |-- mode_test.go |-- utils.go 杂碎 |-- utils_test.go 接下来的章节将按照各个模块进行合-分讲解，让优秀不再神秘。分析版本为v1.2。\n"},{"id":1,"href":"/SCA/docs/gin-gonic_gin/0101_flow/","title":"0101 Flow","section":"gin-gonic/gin","content":"流程 #  从不同的视角去看待web应用的流程：\n 使用者视角：程序员如何使用gin来编写业务逻辑 应用初始化：当进程启动时gin内部是如何初始化的 请求生命周期：当一个HTTP请求来到服务器时后如何转化为响应  说这些之前了解一下Context这个结构体\nContext结构体 #  简单介绍一下gin框架里面最重要的结构体Context，另外一个最重要的结构体是Engine，它作为单例存在；而Context是从对象池中得到。\n// Context作为一个数据结构在中间件中传递本次请求的各种数据、管理流程，进行响应 // context.go:40 type Context struct { // ServeHTTP的第二个参数: request Request *http.Request // 用来响应 Writer ResponseWriter writermem responseWriter // URL里面的参数，比如：/xx/:id Params Params // 参与的处理者（中间件 + 请求处理者列表） handlers HandlersChain // 当前处理到的handler的下标 index int8 // Engine单例 engine *Engine // 在context可以设置的值 Keys map[string]interface{} // 一系列的错误 Errors errorMsgs // Accepted defines a list of manually accepted formats for content negotiation. Accepted []string } // response_writer.go:20 type ResponseWriter interface { http.ResponseWriter //嵌入接口 http.Hijacker //嵌入接口 http.Flusher //嵌入接口 http.CloseNotifier //嵌入接口 // 返回当前请求的 response status code Status() int // 返回写入 http body的字节数 Size() int // 写string WriteString(string) (int, error) //是否写出 Written() bool // 强制写htp header (状态码 + headers) WriteHeaderNow() } // response_writer.go:40 // 实现 ResponseWriter 接口 type responseWriter struct { http.ResponseWriter size int status int } type errorMsgs []*Error // 每当一个请求来到服务器，都会从对象池中拿到一个context。其函数有： // **** 创建 reset() //从对象池中拿出来后需要初始化 Copy() *Context //克隆，用于goroute中 HandlerName() string //得到最后那个处理者的名字 Handler() //得到最后那个Handler // **** 流程控制 Next() // 只能在中间件中使用，依次调用各个处理者 IsAborted() bool Abort() // 废弃 AbortWithStatusJson(code int, jsonObj interface{}) AbortWithError(code int, err error) *Error // **** 错误管理 Error(err error) *Error // 给本次请求添加个错误。将错误收集然后用中间件统一处理（打日志|入库）是一个比较好的方案 // **** 元数据管理 Set(key string, value interface{}) //本次请求用户设置各种数据 (Keys 字段) Get(key string)(value interface{}, existed bool) MustGet(key string)(value interface{}) GetString(key string) string GetBool(key string) bool GetInt(key string) int GetInt64(key string) int64 GetFloat64(key string) float64 GetTime(key string) time.Time GetDuration(key string) time.Duration GetStringSlice(key string) []string GetStringMap(key string) map[string]interface{} GetStringMapString(key string) map[string]string GetStringMapStringSlice(key string) map[string][]string // **** 输入数据 //从URL中拿值，比如 /user/:id =\u0026gt; /user/john Param(key string) string //从GET参数中拿值，比如 /path?id=john GetQueryArray(key string) ([]string, bool) GetQuery(key string)(string, bool) Query(key string) string DefaultQuery(key, defaultValue string) string GetQueryArray(key string) ([]string, bool) QueryArray(key string) []string //从POST中拿数据 GetPostFormArray(key string) ([]string, bool) PostFormArray(key string) []string GetPostForm(key string) (string, bool) PostForm(key string) string DefaultPostForm(key, defaultValue string) string // 文件 FormFile(name string) (*multipart.FileHeader, error) MultipartForm() (*multipart.Form, error) SaveUploadedFile(file *multipart.FileHeader, dst string) error // 数据绑定 Bind(obj interface{}) error //根据Content-Type绑定数据 BindJSON(obj interface{}) error BindQuery(obj interface{}) error //--- Should ok, else return error ShouldBindJSON(obj interface{}) error ShouldBind(obj interface{}) error ShouldBindJSON(obj interface{}) error ShouldBindQuery(obj interface{}) error //--- Must ok, else SetError MustBindJSON(obj interface{}) error ClientIP() string ContentType() string IsWebsocket() bool // **** 输出数据 Status(code int) // 设置response code Header(key, value string) // 设置header GetHeader(key string) string GetRawData() ([]byte, error) Cookie(name string) (string, error) // 设置cookie SetCookie(name, value string, maxAge int, path, domain string, secure, httpOnly bool) Render(code int, r render.Render) // 数据渲染 HTML(code int, name string, obj interface{}) //HTML JSON(code int, obj interface{}) //JSON IndentedJSON(code int, obj interface{}) SecureJSON(code int, obj interface{}) JSONP(code int, obj interface{}) //jsonp XML(code int, obj interface{}) //XML YAML(code int, obj interface{}) //YAML String(code int, format string, values ...interface{}) //string Redirect(code int, location string) // 重定向 Data(code int, contentType string, data []byte) // []byte File(filepath string) // file SSEvent(name string, message interface{}) // Server-Sent Event Stream(step func(w io.Writer) bool) // stream // **** 实现 context.Context 接口(GOROOT中) 使用者视角 #   编程其实是尝试的过程，通过反馈不断的修正。\n 简单的例子 #  // step1: 得到gin go get github.com/gin-gonic/gin // step2: 编辑main.go import ( \u0026quot;net/http\u0026quot; \u0026quot;github.com/gin-gonic/gin\u0026quot; ) func main() { // 创建一个Engine r := gin.New() // 定义一个处理者 r.GET(\u0026quot;/\u0026quot;, func(c *gin.Context) { c.String(http.StatusOK, \u0026quot;Hello World!\u0026quot;) }) // 再定义一个处理者 r.POST(\u0026quot;/ping\u0026quot;, func(c *gin.Context) { c.String(http.StatusOK, \u0026quot;pong\u0026quot;) }) // 让其运行起来 r.Run(\u0026quot;0.0.0.0:8888) } // step3: 运行 go run main.go 使用路由组和中间件 #  import ( \u0026quot;net/http\u0026quot; \u0026quot;github.com/gin-gonic/gin\u0026quot; ) func main() { r := gin.New() // 使用日志插件 r.Use(gin.Logger()) r.GET(\u0026quot;/\u0026quot;, func(c *gin.Context) { c.String(http.StatusOK, \u0026quot;Hello world\u0026quot;) }) r.POST(\u0026quot;/ping\u0026quot;, func(c *gin.Context) { c.String(http.StatusOK, \u0026quot;pong\u0026quot;) }) // 使用路由组 authGroup := r.Group(\u0026quot;/auth\u0026quot;, func(c *gin.Context) { token := c.Query(\u0026quot;token\u0026quot;) if token != \u0026quot;123456\u0026quot; { c.AbortWithStatusJSON(200, map[string]string{ \u0026quot;code\u0026quot;: \u0026quot;401\u0026quot;, \u0026quot;msg\u0026quot;: \u0026quot;auth fail\u0026quot;, }) } c.Next() }) // 注册 /auth/info 处理者 authGroup.GET(\u0026quot;/info\u0026quot;, func(c *gin.Context) { c.JSON(200, map[string]string{ \u0026quot;id\u0026quot;: \u0026quot;1234\u0026quot;, \u0026quot;name\u0026quot;: \u0026quot;name\u0026quot;, }) }) r.Run(\u0026quot;0.0.0:8910\u0026quot;) } 很简单的注册就可以让应用跑起来了。\n应用初始化 #  当我们运行 go run main.go 时gin都做了什么呢？\n其实golang原生就支持http请求应用开发，任何golang web框架的本质只能是作为工具集存在的。\n官方文档 Writing Web Applications介绍了如何写一个web应用。\n示例代码：\n// demo1 import ( \u0026quot;net/http\u0026quot; ) func main() { http.HandleFunc(\u0026quot;/info\u0026quot;, func(response http.ResponseWriter, request *http.Request) { response.Write([]byte(\u0026quot;info\u0026quot;)) }) http.ListenAndServe(\u0026quot;:8888\u0026quot;, nil) } // demo2 import ( \u0026quot;net/http\u0026quot; ) type Handle struct{} func (h Handle) ServeHTTP(response http.ResponseWriter, request *http.Request) { switch request.URL.Path { case \u0026quot;/info\u0026quot;: response.Write([]byte(\u0026quot;info\u0026quot;)) default: } } func main() { http.ListenAndServe(\u0026quot;:8888\u0026quot;, Handle{}) } 上面两个代码非常简单，但是就可以在服务器上开始一个web应用。\n而gin的本质也就是使用demo2的代码，进行封装，提供工具函数，方便业务开发。\n回到本章的主题，应用初始化大概的过程包括：\n 创建一个 Engine 对象 注册中间件 注册路由（组）  请求生命周期 #  因为golang原生为web而生而提供了完善的功能，用户需要关注的东西大多数是业务逻辑本身了。\ngin能做的事情也是去把 ServeHTTP(ResponseWriter, *Request) 做得高效、友好。\n一个请求来到服务器了，ServeHTTP 会被调用，gin做的事情包括：\n 路由，找到handle 将请求和响应用Context包装起来供业务代码使用 依次调用中间件和处理函数 输出结果  "},{"id":2,"href":"/SCA/docs/gin-gonic_gin/0200/","title":"200th","section":"gin-gonic/gin","content":"路由 #  本章讨论:\n 路由调用逻辑：流程的流转逻辑 路由内部实现：基树：路由的内部实现  "},{"id":3,"href":"/SCA/docs/gin-gonic_gin/0201_router/","title":"0201 Router","section":"gin-gonic/gin","content":"路由调用逻辑\ngin 对外宣传的高效，很大一部分是说其路由效率。本文内容包括：\n 路由API介绍 路由调用实现逻辑 路由的内部实现  路由API #  设置路由 #  // routergroup.go:20 type IRoutes interface { Use(handlers ...HandlerFunc) IRoutes Handle(httpMethod, relativePath string, handlers ...HandlerFunc) IRoutes Any(relativePath string, handlers ...HandlerFunc) IRoutes GET(relativePath string, handlers ...HandlerFunc) IRoutes POST(relativePath string, handlers ...HandlerFunc) IRoutes DELETE(relativePath string, handlers ...HandlerFunc) IRoutes PATCH(relativePath string, handlers ...HandlerFunc) IRoutes PUT(relativePath string, handlers ...HandlerFunc) IRoutes OPTIONS(relativePath string, handlers ...HandlerFunc) IRoutes HEAD(relativePath string, handlers ...HandlerFunc) IRoutes StaticFile(relativePath, filepath string) IRoutes Static(relativePath, root string) IRoutes StaticFS(relativePath string, fs http.FileSystem) IRoutes } // routergroup.go:15 type IRouter interface { IRoutes Group(string, ...HandlerFunc) *RouterGroup } RouteGroup的获取 #   Engine嵌入了RouteGroup，它本身就实现了IRoutes接口，gin.New() 和 gin.Default() 可以得到Engine对象 Engine.Group(relativePath string, handlers \u0026hellip;HandlerFunc)可以得到一个新的RouteGroup  路由的命中 #  初始化时将 gin.go:handleHTTPRequest 设置为http请求的处理者，它会将请求进行预处理后去处查找命中的处理者（列表），然后去执行。 这个是调用逻辑，我们讲具体实现。\n路由的调用逻辑 #  背景知识 #  我们先看 Engine 结构体和路由有关的字段\ngin.go:50 type Engine struct { RouterGroup // 如果true，当前路由匹配失败但将路径最后的 / 去掉时匹配成功时自动匹配后者 // 比如：请求是 /foo/ 但没有命中，而存在 /foo， // 对get method请求，客户端会被301重定向到 /foo // 对于其他method请求，客户端会被307重定向到 /foo RedirectTrailingSlash bool // 如果true，在没有处理者被注册来处理当前请求时router将尝试修复当前请求路径 // 逻辑为： // - 移除前面的 ../ 或者 // // - 对新的路径进行大小写不敏感的查询 // 如果找到了处理者，请求会被301或307重定向 // 比如： /FOO 和 /..//FOO 会被重定向到 /foo // RedirectTrailingSlash 参数和这个参数独立 RedirectFixedPath bool // 如果true，当路由没有被命中时，去检查是否有其他method命中 // 如果命中，响应405 （Method Not Allowed） // 如果没有命中，请求将由 NotFound handler 来处理 HandleMethodNotAllowed bool // 如果true， url.RawPath 会被用来查找参数 UseRawPath bool // 如果true， path value 会被保留 // 如果 UseRawPath是false(默认)，UnescapePathValues为true // url.Path会被保留并使用 UnescapePathValues bool allNoRoute HandlersChain allNoMethod HandlersChain noRoute HandlersChain noMethod HandlersChain //每个http method对应一棵树 trees methodTrees } // gin.go:30 type HandlerFunc func(*Context) type HandlersChain []HandlerFunc // routergroup.go:40 type RouterGroup struct { // 这个路由会参与处理的函数列表 Handlers HandlersChain basePath string // 单例存在 engine *Engine // 是否是根 root bool } 添加路由 #  // routergroup.go:70 func (group *RouterGroup) handle(httpMethod, relativePath string, handlers HandlersChain) IRoutes { // 将basePath和relativePath加起来得到最终的路径 absolutePath := group.calculateAbsolutePath(relativePath) // 将现有的 Handlers 和 handlers合并起来 handlers = group.combineHandlers(handlers) // 将这个route加入到engine.tree group.engine.addRoute(httpMethod, absolutePath, handlers) // 返回 return group.returnObj() } 上面的 addRoute() 的实现：\nfunc (engine *Engine) addRoute(method, path string, handlers HandlersChain) { // 常规检查 assert1(path[0] == '/', \u0026quot;path must begin with '/'\u0026quot;) assert1(method != \u0026quot;\u0026quot;, \u0026quot;HTTP method can not be empty\u0026quot;) assert1(len(handlers) \u0026gt; 0, \u0026quot;there must be at least one handler\u0026quot;) debugPrintRoute(method, path, handlers) // 维护engine.trees root := engine.trees.get(method) if root == nil { root = new(node) engine.trees = append(engine.trees, methodTree{method: method, root: root}) } // 核心，后面一起来讲 root.addRoute(path, handlers) } 查找路由 #  我们看看路由查找逻辑：\ngin.go:340 func (engine *Engine) handleHTTPRequest(c *Context) { httpMethod := c.Request.Method path := c.Request.URL.Path unescape := false // 看是否使用 RawPath if engine.UseRawPath \u0026amp;\u0026amp; len(c.Request.URL.RawPath) \u0026gt; 0 { path = c.Request.URL.RawPath unescape = engine.UnescapePathValues } t := engine.trees // 根据 http method 得到目标树 for i, tl := 0, len(t); i \u0026lt; tl; i++ { if t[i].method == httpMethod { // 目标树找到了，为本次请求路由树的根节点 root := t[i].root // 根据path查找节点 // 核心，后面来讲 handlers, params, tsr := root.getValue(path, c.Params, unescape) if handlers != nil { c.handlers = handlers c.Params = params c.Next() c.writermem.WriteHeaderNow() return } if httpMethod != \u0026quot;CONNECT\u0026quot; \u0026amp;\u0026amp; path != \u0026quot;/\u0026quot; { // 如果 trailing slash redirect，就重定向出去 if tsr \u0026amp;\u0026amp; engine.RedirectTrailingSlash { redirectTrailingSlash(c) return } // fix path if engine.RedirectFixedPath \u0026amp;\u0026amp; redirectFixedPath(c, root, engine.RedirectFixedPath) { return } } // 没找到 break } } // 如果是因为HTTP method有误，回复这个 if engine.HandleMethodNotAllowed { for _, tree := range engine.trees { if tree.method != httpMethod { if handlers, _, _ := tree.root.getValue(path, nil, unescape); handlers != nil { c.handlers = engine.allNoMethod serveError(c, 405, default405Body) return } } } } // 交给 NotRoute （404） c.handlers = engine.allNoRoute serveError(c, 404, default404Body) } "},{"id":4,"href":"/SCA/docs/gin-gonic_gin/0202_radix_tree/","title":"0202 Radix Tree","section":"gin-gonic/gin","content":"路由内部实现：基树 #  路由的内部实现 #  前面我们把route接口层面的调用都过了一遍，gin的代码调用还是很简单直接的。\n 程序 = 数据结构 + 算法\n gin的核心结构体叫 Engine ，那引擎到底在哪呢？我想就是它的路由实现。接下来我们去一窥究竟。\n基树 #  基树维基百科 详细介绍了基树这种数据结构。它是gin的router的底层数据结构。\n具体实现 #  node的数据结构： // tree.go:88 type node struct { // 相对路径 path string // 索引 indices string // 子节点 children []*node // 处理者列表 handlers HandlersChain priority uint32 // 结点类型：static, root, param, catchAll nType nodeType // 最多的参数个数 maxParams uint8 // 是否是通配符(:param_name | *param_name) wildChild bool } 基树的构建 #  构建的过程其实是不断寻找最长前缀的过程。\n基树的查找 #  基数的查找不抠细节的话其实就是从根节点一直 匹配当前节点和匹配孩子节点，直到找到匹配的节点，返回handlers。\n代码在： tree.go:365\n"},{"id":5,"href":"/SCA/docs/gin-gonic_gin/0301_request/","title":"0301 Request","section":"gin-gonic/gin","content":"请求 #  其实在流程 中就有讲到。\n在请求来到服务器后，Context对象会生成用来串流程： 和请求有关的字段包括:\n// context.go:40 type Context struct { // ServeHTTP的第二个参数: request Request *http.Request // URL里面的参数，比如：/xx/:id Params Params } 获取restful接口的参数 #  在路由解析时会初始化 Params 提供Get函数：\nParam(key string) string 获取请求数据： #  // Header GetHeader(key string) string // c.Request.Body GetRawData() ([]byte, error) // Cookie Cookie(name string) (string, error) //从GET参数中拿值，比如 /path?id=john // 实现原理：调用系统库：*http.Request.URL.Query() GetQueryArray(key string) ([]string, bool) GetQuery(key string)(string, bool) Query(key string) string DefaultQuery(key, defaultValue string) string GetQueryArray(key string) ([]string, bool) QueryArray(key string) []string //从POST中拿数据 // 实现原理：调用系统库：*http.Request.PostForm() 和 *http.Request.MultipartForm.Value GetPostFormArray(key string) ([]string, bool) PostFormArray(key string) []string GetPostForm(key string) (string, bool) PostForm(key string) string DefaultPostForm(key, defaultValue string) string // 文件 // 实现原理：调用系统库：*http.Request.FormFile() FormFile(name string) (*multipart.FileHeader, error) MultipartForm() (*multipart.Form, error) SaveUploadedFile(file *multipart.FileHeader, dst string) error 数据对象化 #  Bind(obj interface{}) error //根据Content-Type绑定数据 BindJSON(obj interface{}) error BindQuery(obj interface{}) error //--- Should ok, else return error ShouldBindJSON(obj interface{}) error ShouldBind(obj interface{}) error ShouldBindJSON(obj interface{}) error ShouldBindQuery(obj interface{}) error //--- Must ok, else SetError MustBindJSON(obj interface{}) error 我们仔细看看实现逻辑\n// 首先有一个Binding接口， //binding/binding.go:27 type Binding interface { // 绑定器的名称 Name() string // 进行数据绑定 Bind(*http.Request, interface{}) error } // 然后有一个矩阵得到binding对象 //binding/binding.go:70 method content-type binding ----------------------------------------------- GET * Form * application/json JSON * application/xml XML * text/xml XML * application/x-protobuf ProtoBuf * application/x-msgpack MsgPack * application/msgpack MsgPack * 其他 Form // 最后还有数据校验，使用的是 `go-playground/validator.v8` 其他工具方法 #  ClientIP() string ContentType() string IsWebsocket() bool "},{"id":6,"href":"/SCA/docs/gin-gonic_gin/0401_response/","title":"0401 Response","section":"gin-gonic/gin","content":"响应 #  其实在流程 中就有讲到。\n在请求来到服务器后，Context对象会生成用来串流程： 和请求有关的字段包括:\n// context.go:40 type Context struct { // 用来响应 Writer ResponseWriter writermem responseWriter } // response_writer.go:20 type ResponseWriter interface { http.ResponseWriter //嵌入接口 http.Hijacker //嵌入接口 http.Flusher //嵌入接口 http.CloseNotifier //嵌入接口 // 返回当前请求的 response status code Status() int // 返回写入 http body的字节数 Size() int // 写string WriteString(string) (int, error) //是否写出 Written() bool // 强制写htp header (状态码 + headers) WriteHeaderNow() } // response_writer.go:40 // 实现 ResponseWriter 接口 type responseWriter struct { http.ResponseWriter size int status int } 初始化过程 #  在请求来到服务器时，会从对象池中拿到一个Context对象；\n// 1 初始化writermem // gin.go:322 c.writermem.reset(w) func (w *responseWriter) reset(writer http.ResponseWriter) { w.ResponseWriter = writer w.size = noWritten w.status = defaultStatus } // 2 初始化context // gin.go:324 c.reset() func (c *Context) reset() { c.Writer = \u0026amp;c.writermem c.Params = c.Params[0:0] c.handlers = nil c.index = -1 c.Keys = nil c.Errors = c.Errors[0:0] c.Accepted = nil } 设置响应码、cookie、header等 #  // 实现原理：设置c.writermen.status Status(code int) // 设置response code // 实现原理： 调用系统函数 Header(key, value string) // 设置header // 实现原理： 调用系统函数 SetCookie(name, value string, maxAge int, path, domain string, secure, httpOnly bool) 设置返回的数据 #  Render(code int, r render.Render) // 数据渲染 HTML(code int, name string, obj interface{}) //HTML JSON(code int, obj interface{}) //JSON IndentedJSON(code int, obj interface{}) SecureJSON(code int, obj interface{}) JSONP(code int, obj interface{}) //jsonp XML(code int, obj interface{}) //XML YAML(code int, obj interface{}) //YAML String(code int, format string, values ...interface{}) //string Redirect(code int, location string) // 重定向 Data(code int, contentType string, data []byte) // []byte File(filepath string) // file SSEvent(name string, message interface{}) // Server-Sent Event Stream(step func(w io.Writer) bool) // stream 我们仔细看看实现逻辑：\n// 实现有一个 Render接口 // render/render.go:9 type Render interface { Render(http.ResponseWriter) error WriteContentType(w http.ResponseWriter) } // 自己选择具体的实现，有 - JSON - IndentedJSON - SecureJSON - JsonpJSON - XML - String - Redirect - Data - HTML - HTMLDebug - HTMLProduction - YAML - MsgPack // 对应实现进行具体操作，完成数据输出 "},{"id":7,"href":"/SCA/docs/gin-gonic_gin/0501_other/","title":"0501 Other","section":"gin-gonic/gin","content":"其他主题 #  基本上介绍完 gin 框架了，一个非常克制的框架，提供了路由、使用 Context 来封装数据。 golang的原生库对web开发是较为完善的，所有的框架只能是工具集。\n中间件 #  中间件实际上上特殊的 HandleFuc 注册在 Engine.RouterGroup 上，最终会附加到每个节点的handlerList前，每次处理时依次调用。\ngin 提供了几个中间件:\n auth: auth.go，完成基本的鉴权 log: logger.go，完成请求日志输出 recover: recover.go， 完成崩溃处理  错误管理 #  错误管理是指在业务处理中可以将错误不断的设置到context中，然后可以一次性处理，比如记日志。\n// context.go:40 type Context struct { // 一系列的错误 Errors errorMsgs } Error(err error) *Error // 给本次请求添加个错误。将错误收集然后用中间件统一处理（打日志|入库）是一个比较好的方案 元数据管理 #  // context.go:40 type Context struct { // 在context可以设置的值 Keys map[string]interface{} } Set(key string, value interface{}) //本次请求用户设置各种数据 (Keys 字段) Get(key string)(value interface{}, existed bool) MustGet(key string)(value interface{}) GetString(key string) string GetBool(key string) bool GetInt(key string) int GetInt64(key string) int64 GetFloat64(key string) float64 GetTime(key string) time.Time GetDuration(key string) time.Duration GetStringSlice(key string) []string GetStringMap(key string) map[string]interface{} GetStringMapString(key string) map[string]string GetStringMapStringSlice(key string) map[string][]string 路由组 #  import ( \u0026quot;net/http\u0026quot; \u0026quot;github.com/gin-gonic/gin\u0026quot; ) func main() { r := gin.New() // 使用日志插件 r.Use(gin.Logger()) r.GET(\u0026quot;/\u0026quot;, func(c *gin.Context) { c.String(http.StatusOK, \u0026quot;Hello world\u0026quot;) }) // 使用路由组 authGroup := r.Group(\u0026quot;/auth\u0026quot;, func(c *gin.Context) { token := c.Query(\u0026quot;token\u0026quot;) if token != \u0026quot;123456\u0026quot; { c.AbortWithStatusJSON(200, map[string]string{ \u0026quot;code\u0026quot;: \u0026quot;401\u0026quot;, \u0026quot;msg\u0026quot;: \u0026quot;auth fail\u0026quot;, }) } c.Next() }) // 注册 /auth/info 处理者 authGroup.GET(\u0026quot;/info\u0026quot;, func(c *gin.Context) { c.JSON(200, map[string]string{ \u0026quot;id\u0026quot;: \u0026quot;1234\u0026quot;, \u0026quot;name\u0026quot;: \u0026quot;name\u0026quot;, }) }) r.Run(\u0026quot;0.0.0:8910\u0026quot;) } 路由组可以将路由分组管理\n// routergroup.go:15 type IRouter interface { IRoutes Group(string, ...HandlerFunc) *RouterGroup } // routergroup.go:40 type RouterGroup struct { Handlers HandlersChain basePath string engine *Engine root bool } var _ IRouter = \u0026amp;RouterGroup{} // routergroup.go:55 func (group *RouterGroup) Group(relativePath string, handlers ...HandlerFunc) *RouterGroup { return \u0026amp;RouterGroup{ Handlers: group.combineHandlers(handlers), basePath: group.calculateAbsolutePath(relativePath), engine: group.engine, } } 其实 Engine 就实现了 IRouter 接口 就是个 路由组；而路由组是基于路由组产生的。\n其他 #  我一直没有搞明白 content negotiation (context.go:750)是干嘛用的。\n"},{"id":8,"href":"/SCA/docs/tal-tech_go-zero/core/01_bloom_filter/","title":"01 Bloom Filter","section":"Core","content":"布隆过滤器 #  包 core/bloom 提供了一个布隆过滤器的实现。\n什么是 布隆过滤器？ #  布隆过滤器是 burton Bloom 在 1970年提出来的一个 用来处理 元素是否在集合中的 方法。对于海量数据，使用布隆过滤器在判定某个元素是否在其中时具有极高的空间效率和查询效率。它不会漏判，但是可能误判（不在里面的被认为在里面）。\n布隆过滤器基本原理 #  布隆过滤器由一个超大的位数组A和M个hash函数组成，它支持两种操作：\n 添加元素K：  将K依次交给M个函数运算，得到M个下标，将A中下标的值都设置为1   查询元素K：  将K依次交给M个函数运算，得到M个下标，如果A中这些下标的值都是1，则代表元素（可能）存在，不然就是（一定）不存在    不支持删除。\n布隆过滤器的误差率 #  有专门的分析。\n布隆过滤器的应用 #   判断某个邮箱地址在不在上亿个邮箱地址中 判断某个URL爬虫是否扒取过 判断某个数据在数据库是否存在 \u0026hellip;  go-zero布隆过滤器的实现 #  go-zero 中使用redis来存储位数组，自定义了hash函数。\nhash 函数 #  // 根据 key 得到 M 个下标 func (f *BloomFilter) getLocations(data []byte) []uint { locations := make([]uint, maps) // maps = 14 \tfor i := uint(0); i \u0026lt; maps; i++ { // 每次将 i 追加到数据本身中，使用同一个hash函数得到不同的下标 \thashValue := hash.Hash(append(data, byte(i))) locations[i] = uint(hashValue % uint64(f.bits)) } // 会得到一个长度为14的数组，存储者14个下标 \treturn locations } 位数组 #  直接使用了redis的 bits相关的功能，执行lua脚本，将 locations 里面的数据存储到redis中。\n// 添加元素的的脚本 setScript = ` for _, offset in ipairs(ARGV) do redis.call(\u0026#34;setbit\u0026#34;, KEYS[1], offset, 1) end ` // 查询元素的脚本 testScript = ` for _, offset in ipairs(ARGV) do if tonumber(redis.call(\u0026#34;getbit\u0026#34;, KEYS[1], offset)) == 0 then return false end end return true ` "},{"id":9,"href":"/SCA/docs/tal-tech_go-zero/core/02_break/","title":"02 Break","section":"Core","content":"熔断器 #  包 `core/break 提供了一个熔断器的接口和两套实现。\n什么是 熔断器？ #  服务端经常会面临的一个问题是服务器负载过高，比如某个热点新闻导致流量短时间激增，这个时候如果不做相应的保护，服务端可能发生宕机导致直接不可用。处理这种情况一般会：\n 服务降级：比如返回静态数据 服务熔断：对部分请求直接返回服务不可用，对其他请求继续提供服务  熔断器就是完成熔断功能的组件。它应该决定是否为当前请求提供正常服务，还是直接拒绝。\ngo-zero熔断器的实现 #  接口定义 #  type ( // 判断一个错误返回是否依旧是成功的 \tAcceptable func(err error) bool Breaker interface { // Name returns the name of the netflixBreaker. \tName() string // 判断请求是否被允许  // 如果允许，调用方需要在调用成功后调用 promise.Accept(),失败后调用 promise.Reject  // 如果不被允许（限流了），返回的是 ErrServiceUnavailable \tAllow() (Promise, error) // DoWithFallbackAcceptable  // - 在未被限流时执行req  // - 被限流时执行fallback（回退） \t// - acceptable 检查 req 是否调用成功，即便req返回的err不是nil \tDoWithFallbackAcceptable(req func() error, fallback func(err error) error, acceptable Acceptable) error // DoWithFallbackAcceptable 的简化版  // acceptable 为 err == nil \tDoWithFallback(req func() error, fallback func(err error) error) error // DoWithFallbackAcceptable 的简化版  // fallback 逻辑为：nil 不做回退 \tDoWithAcceptable(req func() error, acceptable Acceptable) error // DoWithFallbackAcceptable 的简化版  // acceptable 为 err == nil  // fallback 逻辑为：nil 不做回退 \tDo(req func() error) error } ) 可以看见，类库实现的Breaker里面本质上只有两个接口：\n// 判断是否被限流 Allow() (Promise, error) // 确定是否被限流 // - 如果限流了就执行 fallback // - 如果没有限流就执行 req，使用 acceptable 确定是否执行成功，来执行后续的行为（本质上是Promise） DoWithFallbackAcceptable(req func() error, fallback func(err error) error, acceptable Acceptable) error 功能实现原理 #  实现是参考了Google的方案。先对方案进行阐述：\nA通过调用Redis完成自身业务，因为Redis的负载是有限的，一般会和A协商好Redis对A的容量，如果超限了就拒绝对A的调用。\n这里面有个问题，拒绝服务会耗用资源，比如：\n 如果提供服务的代价比拒绝服务的代价还要小 如果请求太多了，拒绝本身也很昂贵  Google给出个他们实践下来效果良好的方案自适应限流：在Redis被访问时（这个逻辑A中调用，但是由Redis客户端类库提供）Redis客户端库自己会在Redis服务拒绝后开始按一定比例直接丢弃A对Redis的请求（连网络请求都不发送）。\n丢弃的概率为： max(0, (一段时间内的请求总数 - K * 一段时间内的请求被正常处理数) / (一段时间内的请求总数 + 1) )\n其中K是一个变量，举个例子，当K = 1 时，一个请求会有 (被拒绝的数量 / 总数量) 的概率直接被拒绝，假设Redis能处理 200 个请求：\n 当请求数量为200时，被拒绝的概率是0，被处理的数量为200 当请求数量为400时，Redis服务端会拒绝200个请求，可以得到被拒绝的概率是0.5，这时候类库会开始将200个请求直接丢弃掉，下一刻又回到 状态1  这是个静态的估计，实际中请求总数是动态变化的，被拒绝的数量也是变化的。\nK的含义是：K越大，被拒绝的概率就越小，后端的压力就会越大。\nGoogle使用K=2，期望服务端能够正常处理请求。\n注意，这个算法在零星请求的情况下表现得不好，当请求量开始增加时，服务端的反馈会感觉过慢。\n功能实现细节 #  知道了原理，实现细节就很好理解了。\nfunc (b *googleBreaker) accept() error { // 从 RollingWindow 中得到当前的情况 \taccepts, total := b.history() // k = 1.5 \tweightedAccepts := b.k * float64(accepts) // protection = 5,做预留了,得到丢弃概率 \t// https://landing.google.com/sre/sre-book/chapters/handling-overload/#eq2101 \tdropRatio := math.Max(0, (float64(total-protection)-weightedAccepts)/float64(total+1)) // 丢弃概率为0，确保当前的限流状态是关闭的 \tif dropRatio \u0026lt;= 0 { // 直接返回 接受请求 \treturn nil } // 按概率进行丢弃 \tif b.proba.TrueOnProba(dropRatio) { return ErrServiceUnavailable } return nil } 延展 #  限流器处理Google的这个自适应的解决方案，还包括几个经典的方案：\n  固定窗口：最直接的解决方案，计算周期内总数，超了就限流\n 计数周期太大会导致误差，比如周期为1秒，那么在1秒内相隔的两毫秒的流量可以是最大限流的两倍    滑动窗口：是计数器的升级版，将计算周期减小，使用多个计数器\n   令牌桶：令牌已一定的速度落入桶里面，请求过来时拿一个，如果没拿到就是被限流了   漏斗：将所有的请求排队，从漏斗里面一一出来  "},{"id":10,"href":"/SCA/docs/tal-tech_go-zero/core/03_collection/","title":"03 Collection","section":"Core","content":"集合 #  包 core/collection 实现了各种典型集合类型\nRollingWindow #  限流的方案在 熔断器 里面讲过，Rolling Window 就是一个经典的算法。\n为了解决计算一段时间Interval的请求次数，滑动窗口算法的做法为：将计算周期切成N个Bucket，每个请求过来后，将请求放入对应的Bucket中，当要计算window有多少个请求时，把相关所有的bucket的数据累计起来即可。\n我们先看看数据结构定义：\ntype RollingWindow struct { lock sync.RWMutex // 有多少个计数器 size int // 每个计算器的计数周期 interval time.Duration // 窗口，由多个Bucket组成 win *window // 窗口的偏移，范围为 [0, size) offset int // 最后一次更新的时间 lastTime time.Duration ignoreCurrent bool } type window struct { buckets []*Bucket // 一个window有多个Bucket size int } type Bucket struct { Sum float64 Count int64 } 我们再看看行为定义：\n// 添加个数 func (rw *RollingWindow) Add(v float64) // 通过这个函数拿到当前的状态 // 会找到多个Bucket，需要总数的话直接累加即可 func (rw *RollingWindow) Reduce(fn func(b *Bucket)) 其实算法也不是那么的高深，一个滑动窗口由多个bucket组成：\n 每次往窗口里面添加时：清理过期的bucket后找到目标bucket加入 每次要看窗口的个数是：找到目标的bucket列表，依次查看其Sum和Count即可  假设需求是一分钟限流60次，创建一个size为6，interval为10s的滑动窗口对象。\n   时间，行为 总数Count/Sum 第0个bucketCount/Sum 第1个 2 3 4 5     第8s，新增20个请求 20 / 20 20 / 20 0 / 0 0 / 0 0 / 0 0 / 0 0 / 0   第18s，新增10个请求 30 / 30 20 / 20 10 / 10 0 / 0 0 / 0 0 / 0 0 / 0   第58s，新增15个请求 45 / 45 20 / 20 10 / 10 0 / 0 0 / 0 0 / 0 15 / 15   第78s，新增25个请求  0 / 0 25 / 25 0 / 0 0 / 0 0 / 0 15 / 15    TimingWheel #  对于延迟执行任务，TimingWheel是一个常用的数据结构。一般而言，时间轮会有一个时间间隔，每多久执行一次。然后往里面加任务，一般任务会有一个delay的属性，表示延时多久执行\n每个时间轮会有多个槽点，每个槽点对应的是一个任务列表。每过一个时间间隔，就去执行下一个槽点对应的任务。\n我们先看看每个任务的数据结构：\ntype timingEntry struct { baseEntry value interface{} circle int diff int removed bool } type baseEntry struct { // 延迟多长时间执行 \tdelay time.Duration // 任务的key \tkey interface{} } 每个任务包括：\n circle(层)，如果circle==0，那就是当前执行，不然circle\u0026ndash;，继续等待机会。 在实现细节上，任务还包含diff属性，是移动任务是的偏移量，在被执行时如果diff\u0026gt;0，就需要移动到后面的槽点（这个设计是为了简化移动任务的实现复杂度）  我们看看类库的实现。\n时间轮的基本数据结构：\ntype TimingWheel struct { // 多长时间触发一次 \tinterval time.Duration // 内置的定时器 \tticker timex.Ticker // 槽点的个数 \tnumSlots int // 个数为numSolts的槽点列表 \tslots []*list.List // 一个冗余数据，任务的key为key，为了确认同名的任务是否已经存在 \ttimers *SafeMap // 当前的位置 \ttickedPos int execute Execute setChannel chan timingEntry moveChannel chan baseEntry // 标识任务被删除的chan \tremoveChannel chan interface{} // 标识任务被放弃执行 \tdrainChannel chan func(key, value interface{}) // 标识停止的chan \tstopChannel chan lang.PlaceholderType } 时间轮的行为包括：\n 新增一个任务 往后移动一个任务 删除一个任务 清空时间轮 停止时间轮  // 添加/更新任务， 同步操作是写入setChannel // 异步操作是： // 如果任务存在（timer这个冗余的数据结构），进行更新存在 // 任务不存在，将其加入对应的槽点的任务列表中即可 func (tw *TimingWheel) SetTimer(key, value interface{}, delay time.Duration) // 移动任务，往后延迟被执行的时间，同步操作是写入 moveChannel // 如果delay（后移的时间）小于interval，直接执行 // 不然，将任务移动到适当的position和circle func (tw *TimingWheel) MoveTimer(key interface{}, delay time.Duration) // 移除任务，同步操作是写入 removeChannel // 异步实现是将 timers 中对应的任务直接设置为 removed func (tw *TimingWheel) RemoveTimer(key interface{}) // 放弃执行，同步操作是写入drainChannel // 异步实现是将solts的每个元素拿出来（是一个列表），依次将每个结点的key和value交个fn执行，然后删除节点 // 执行完成后，slots的每个元素都是空数组 func (tw *TimingWheel) Drain(fn func(key, value interface{})) // 停止，同步操作是关闭 stopChannel // 异步操作是停止 ticker func (tw *TimingWheel) Stop() 最重要的操作 其实是每次 ticker 被触发时的任务处理逻辑： 先得到当前的槽点： (tickedPos + 1) % numSlots，得到一个链表 对链表的每个元素依次处理：\n 如果任务已经被设置为removed，直接移除即可 如果circle\u0026gt;0，circle\u0026ndash;，退出处理（说明它不再本周期） 如果diff大于0，找到合适的位置，加入，把本节点删除（其实是move的后续操作） 这时候就是是时候开始执行任务了  时间轮被创建后，异步就开始监听各个chan来执行上面的逻辑了：\nfunc (tw *TimingWheel) run() { for { select { // 任务执行定时器 \tcase \u0026lt;-tw.ticker.Chan(): tw.onTick() // 任务添加/更新 \tcase task := \u0026lt;-tw.setChannel: tw.setTask(\u0026amp;task) // 任务删除 \tcase key := \u0026lt;-tw.removeChannel: tw.removeTask(key) // 任务往后移动 \tcase task := \u0026lt;-tw.moveChannel: tw.moveTask(task) // 任务全部清空 \tcase fn := \u0026lt;-tw.drainChannel: tw.drainAll(fn) // 停止 \tcase \u0026lt;-tw.stopChannel: tw.ticker.Stop() return } } } SafeMap #  golang 里面的map是非并发安全的，并发读写map会panic。官方库提供了 sync.Map 可以直接使用。\n类库提供的 safemap 除了通过加锁解决并发的问题，还解决了一个官方库某些版本才有的bug。\n本身应该能用到的地方不多，但还是简单分析一下思路。\nsafe map 定义和接口：\ntype SafeMap struct { lock sync.RWMutex deletionOld int deletionNew int dirtyOld map[interface{}]interface{} dirtyNew map[interface{}]interface{} } func (m *SafeMap) Del(key interface{}) func (m *SafeMap) Get(key interface{}) (interface{}, bool) func (m *SafeMap) Set(key, value interface{}) func (m *SafeMap) Size() int 我们简单的看一下Del的实现即可：\nfunc (m *SafeMap) Del(key interface{}) { m.lock.Lock() // 从两个map里面删除元素 \tif _, ok := m.dirtyOld[key]; ok { delete(m.dirtyOld, key) m.deletionOld++ } else if _, ok := m.dirtyNew[key]; ok { delete(m.dirtyNew, key) m.deletionNew++ } // 其实，如果上面两个ok都是false，可以直接退出了  // 处理 old map，如果 old 的被删除的次数到阈值并且长度小于某个值 \tif m.deletionOld \u0026gt;= maxDeletion \u0026amp;\u0026amp; len(m.dirtyOld) \u0026lt; copyThreshold { // 1 就将old的所有元素放入new \tfor k, v := range m.dirtyOld { m.dirtyNew[k] = v } // 2 new 赋值给 old（old整体被释放） \tm.dirtyOld = m.dirtyNew m.deletionOld = m.deletionNew // 3 将new直接初始化 \tm.dirtyNew = make(map[interface{}]interface{}) m.deletionNew = 0 } // 对 new 也来一遍同样的操作 \tif m.deletionNew \u0026gt;= maxDeletion \u0026amp;\u0026amp; len(m.dirtyNew) \u0026lt; copyThreshold { for k, v := range m.dirtyNew { m.dirtyOld[k] = v } m.dirtyNew = make(map[interface{}]interface{}) m.deletionNew = 0 } m.lock.Unlock() } Set #  这个也是很简单。\n接口定义：\ntype Set struct { data map[interface{}]lang.PlaceholderType // 就是 struct{} tp int } func (s *Set) Add{Type}(ss ...string) func (s *Set) Contains(i interface{}) bool func (s *Set) Keys() []interface{} func (s *Set) Remove(i interface{}) func (s *Set) Count() int set 支持各种类型，外加类型检查，要是有泛型，事情就会简单很多。\n另外，因为是没有锁的map，是并发不安全的。\n实现大家通过看数据结构就能猜到了，就不多讲了。\nRing #  类库实现了一个定长环。\n接口定义如下：\ntype Ring struct { elements []interface{} index int } func (r *Ring) Add(v interface{}) func (r *Ring) Take() []interface{} 实现本身没有太多的内容，简单描述：\n 每次添加元素，index都前进一格（可能覆盖旧元素） 获取则是从index所在的地方开始，取被设置了的元素。  Queue #  Queue 是典型的 FIFO 数据类型。\n接口定义如下：\ntype Queue struct { lock sync.Mutex elements []interface{} size int head int tail int count int } func (q *Queue) Empty() bool func (q *Queue) Put(element interface{}) func (q *Queue) Take() (interface{}, bool) 这个其实也是很常规的一种数据结构，简单描述：\n 进队列：如果满了，就扩容size个元素，然后在 elements上追加元素 出队列：如果size为0，直接返回nil；不然就更新head和count，返回元素  "},{"id":11,"href":"/SCA/docs/tal-tech_go-zero/core/04_executor/","title":"04 Executor","section":"Core","content":"执行器 #  包 core/executors 实现了各种类型的执行器。\n   执行器类型 执行器使用场景     PeriodicalExecutor 每隔一段时间执行一次   BulkExecutor 凑够多个执行一次   ChunkExecutor 凑够多个字节执行一次   DelayExecutor 延迟一段时间后执行   LessExecutor 一段时间内最多执行一次    满足条件周期触发 #  PeriodicalExecutor 是任务在时间上的聚集，BulkExecutor 是时间+任务数， ChunkExecutor 是 时间+字节数。它们都是任务在一定条件下的触发。\n类库在实现时，提出了一个任务容器的接口，来描述触发条件和任务的执行方式：\ntype TaskContainer interface { // 添加任务，返回是否需要执行任务了  // 对于 BulkExecutor，就是任务数量到了 \tAddTask(task interface{}) bool // 执行任务 \tExecute(tasks interface{}) // 移除所有任务，并返回它们 \tRemoveAll() interface{} } 作为BulkExecutor和ChunkExecutor的基础，PeriodicalExecutor的接口如下：\n// 添加一个任务 func (pe *PeriodicalExecutor) Add(task interface{}) // 将所有的任务取出并执行 func (pe *PeriodicalExecutor) Flush() bool // Wait 会阻塞直到所有的任务都执行完成 func (pe *PeriodicalExecutor) Wait() // 同步执行（就Executor定位而言，这是个多余的API？） func (pe *PeriodicalExecutor) Sync(fn func()) BulkExecutor和ChunkExecutor 组合了 PeriodicalExecutor，通过复用上面的接口对外提供功能，并且实现了各自的TaskContainer。\n延迟触发和限流触发 #  DelayExecutor 的实现为协程执行：定时器后触发\nfunc (de *DelayExecutor) Trigger() { de.lock.Lock() defer de.lock.Unlock() // 只触发一次 \tif de.triggered { return } de.triggered = true threading.GoSafe(func() { // 开协程 \ttimer := time.NewTimer(de.delay) defer timer.Stop() // 等待 \t\u0026lt;-timer.C de.lock.Lock() de.triggered = false de.lock.Unlock() // 执行 \tde.fn() }) } LessExecutor 的实现为：判断上次触发时间距离现在是否超过预先设定的时间间隔，如果是就触发\nfunc (le *LessExecutor) DoOrDiscard(execute func()) bool { now := timex.Now() lastTime := le.lastTime.Load() if lastTime == 0 || lastTime+le.threshold \u0026lt; now { le.lastTime.Set(now) execute() return true } return false } "},{"id":12,"href":"/SCA/docs/tal-tech_go-zero/core/05_fx/","title":"05 Fx","section":"Core","content":"执行器 #  包 core/fx 实现了流式运算的API。\nJava里面有流式运算相关的API。Stream 就如同一个迭代器（Iterator），单向，不可往复，数据只能遍历一次，遍历过一次后即用尽了，就好比流水从面前流过，一去不复返。而和迭代器又不同的是，Stream 可以并行化操作，迭代器只能命令式地、串行化操作。顾名思义，当使用串行方式去遍历时，每个 item 读完后再读下一个 item。而使用并行去遍历时，数据会被分成多个段，其中每一个都在不同的线程中处理，然后将结果一起输出。\nStream的数据结构 #  Stream只有一个数据成员：\ntype Stream struct { // 所有的数据都在chan里面 \tsource \u0026lt;-chan interface{} } Stream的工厂方法 #  创建流对象本质是是把多个同类型的元素放入chan中，类库提供了如下的工厂方法：\ntype GenerateFunc func(source chan\u0026lt;- interface{}) func From(generate GenerateFunc) Stream func Just(items ...interface{}) Stream func Range(source \u0026lt;-chan interface{}) Stream Stream的API #  对于Stream，有如下API：\n 元素处理API  // 将n个数据放入新的Stream中 func (p Stream) Buffer(n int) Stream // 取 Top N func (p Stream) Head(n int64) Stream // 取 Head N func (p Stream) Tail(n int64) Stream // 排序元素 func (p Stream) Sort(less LessFunc) Stream // 反转元素 func (p Stream) Reverse() Stream // 将元素分组，Stream的chan里面每个元素为一组原始的元素 func (p Stream) Group(fn KeyFunc) Stream // 将元素分组，Stream的chan里面只有一个元素，为原始的所有的元素 func (p Stream) Merge() Stream // 过滤元素 func (p Stream) Filter(fn FilterFunc, opts ...Option) Stream // 去重 func (p Stream) Distinct(fn KeyFunc) Stream // 遍历每个元素（但是什么都不做） func (p Stream) Done() // 将所有的元素交给fn处理 func (p Stream) ForAll(fn ForAllFunc) // 将所有的元素交给fn处理 func (p Stream) ForEach(fn ForEachFunc)  并行运算API  type MapFunc func(item interface{}) interface{} // 将每个元素使用fn转换为另外一个元素，调用Walk完成任务 func (p Stream) Map(fn MapFunc, opts ...Option) Stream type ParallelFunc func(item interface{}) // 并行处理每个元素。它和Map很类似，会在Walk完成后调用Done()方法等待所有的元素都执行完成 func (p Stream) Parallel(fn ParallelFunc, opts ...Option) type WalkFunc func(item interface{}, pipe chan\u0026lt;- interface{}) // 并发的处理每个元素 func (p Stream) Walk(fn WalkFunc, opts ...Option) Stream type ReduceFunc func(pipe \u0026lt;-chan interface{}) (interface{}, error) // 将所有的元素交个 fn处理 func (p Stream) Reduce(fn ReduceFunc) (interface{}, error)  其他API  // 计算元素个数 func (p Stream) Count() (count int) 源码分析 #  具体的实现本质上是 chan 和 WaitGroup的使用。举两个例子：\n 过滤元素  func (p Stream) Filter(fn FilterFunc, opts ...Option) Stream { return p.Walk(func(item interface{}, pipe chan\u0026lt;- interface{}) { if fn(item) { // 如果元素符合要放进去 \tpipe \u0026lt;- item } }, opts...) }  有并发数限制的walk  func (p Stream) walkLimited(fn WalkFunc, option *rxOptions) Stream { pipe := make(chan interface{}, option.workers) go func() { var wg sync.WaitGroup // pool 的size为并发数的个数，用它来控制并发数 \tpool := make(chan lang.PlaceholderType, option.workers) for { // 占用一个worker \tpool \u0026lt;- lang.Placeholder item, ok := \u0026lt;-p.source if !ok { // 所有的元素都用完了，退出循环  // 释放一个worker \t\u0026lt;-pool break } // 新增一个执行的任务 \twg.Add(1) // better to safely run caller defined method \tthreading.GoSafe(func() { defer func() { // 完成一个任务 \twg.Done() // 释放worker \t\u0026lt;-pool }() // 进行任务 \tfn(item, pipe) }) } // 阻塞等待 \twg.Wait() close(pipe) }() return Range(pipe) } "},{"id":13,"href":"/SCA/docs/tal-tech_go-zero/core/06_hash/","title":"06 Hash","section":"Core","content":"一致性hash #  状态：编辑中\n包 core/hash 实现了一个一致性hash。\nhash 和 一致性hash #  hash函数将一个字符串（字节数组）转换为一个数值，比如md5。\n在业务开发中，经常会使用hash函数将数据打散到多个存储实例上，比如：\n 数据库水平分表：hash(用户的名字) 后和总表数取模确定存储在哪张表中 缓存集群挑选：hask(key) 后和 缓存集群格式取模确定数据缓存在哪个缓存集群中  realAddr = hash(key) % node_count 这种方式，在instance_count 不变的情况下是工作良好的，但是真实的生产环境却是动态的，就会有如下问题：\n 容错性：实例宕机了，某个实例下线后，最坏情况（第一个实例下线）会导致所有的数据都失效，最好情况（最后一个实例下线）是 1/n 的数据失效 扩展性：添加新实例同上  一致性hash就是用来解决这个问题的。\n普通的算法是将N个物理节点组成一个环，通过和N取模确定到底使用哪个具体的节点，每个节点对应一个物理节点\n一致性hash先得到一个有N个虚拟节点的环，我们先认为N = 2^32 - 1。\n 将每个机器节点hash后与N取模能够得到机器在虚拟环的位置P 通过Key和N取模确定是哪个虚拟节点n 顺着虚拟环顺时针查找到的第一个P就是需要使用的物理节点  我们来分析一下一致性hash的表现：\n 容错性：实例宕机了，某个实例下线后，总是 1/n 的数据失效 扩展性：添加新实例，总是少于 1/n的数据受影响  有一个地方需要特别注意一下： 将每个机器节点hash后与N取模能够得到机器在虚拟环的位置P 这步，如果做得不够均匀，就会导致 数据倾斜，也就是每个物理节点的负载不一样。\n比如有N物理节点，它们的P 相减为 2^32 / N 才比较对，极端情况P相差1，那么就有一台物理节点几乎承担所有的负载。\n解决这个问题的一种方法为对每个物理节点进行多个hash，每次计算的结果为一个虚拟节点。同一个物理节点的多个虚拟节点都是该物理节点服务的范围。通过多个hash，降低数据倾斜的概率。\n一致性hash的API #  type ( HashFunc func(data []byte) uint64 ConsistentHash struct { // 将key转换为int的函数 \thashFunc HashFunc // 副本的数量，也就是上面虚拟节点的数量 \treplicas int // \tkeys []uint64 // \tring map[uint64][]interface{} // 用来确认某个节点是否存在的冗余数据 \tnodes map[string]lang.PlaceholderType lock sync.RWMutex } ) Add(node interface{}) AddWithReplicas(node interface{}, replicas int) AddWithWeight(node interface{}, weight int) Get(v interface{}) (interface{}, bool) Remove(node interface{}) "},{"id":14,"href":"/SCA/docs/tal-tech_go-zero/core/09_other/","title":"09 Other","section":"Core","content":"其他 #     包 说明     cmdline 命令行接收相关的工具函数   codec 加解密/编码相关的二次封装   conf yaml/json加解密, kv 的序列化和反序列化   contextx context 的二次封装   errorx error相关的二次封装，包括多个error和原子化操作的error   filex 文件相关的封装，比如读取文件第一行/最后一行    "}]