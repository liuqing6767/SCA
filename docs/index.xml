<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>SourceCodeAnalysis</title>
    <link>/SCA/</link>
    <description>Recent content on SourceCodeAnalysis</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language><atom:link href="/SCA/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title></title>
      <link>/SCA/docs/gin-gonic_gin/0001_preface/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/SCA/docs/gin-gonic_gin/0001_preface/</guid>
      <description>源码解析之:gin #  gin 是一个用golang实现的HTTPweb框架。
特性 #  官网上描述，gin的特性包括：
 快：路由使用基数树，低内存，不使用反射； 中间件注册：一个请求可以被一系列的中间件和最后的action处理 奔溃处理：gin可以捕获panic使应用程序可用 JSON校验：将请求的数据转换为JSON并校验 路由组：更好的组织路由的方式，无限制嵌套而不影响性能 错误管理：可以收集所有的错误 内建渲染方式：JSON，XML和HTML渲染方式 可继承：简单的去创建中间件  代码结构 #  |-- binding 将请求的数据对象化并校验 |-- examples 各种列子 |-- json 提供了另外一种json实现 |-- render 响应 |-- gin.go gin引擎所在 |-- gin_test.go |-- routes_test.go |-- context.go 上下文，将各种功能聚焦到上下文（装饰器模式） |-- context_test.go |-- response_writer.go 响应的数据输出 |-- response_writer_test.go |-- errors.go 错误处理 |-- errors_test.go |-- tree.go 路由的具体实现 |-- tree_test.go |-- routergroup.go |-- routergroup_test.go |-- auth.go 一个基本的HTTP鉴权的中间件 |-- auth_test.go |-- logger.</description>
    </item>
    
    <item>
      <title></title>
      <link>/SCA/docs/gin-gonic_gin/0101_flow/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/SCA/docs/gin-gonic_gin/0101_flow/</guid>
      <description>流程 #  从不同的视角去看待web应用的流程：
 使用者视角：程序员如何使用gin来编写业务逻辑 应用初始化：当进程启动时gin内部是如何初始化的 请求生命周期：当一个HTTP请求来到服务器时后如何转化为响应  说这些之前了解一下Context这个结构体
Context结构体 #  简单介绍一下gin框架里面最重要的结构体Context，另外一个最重要的结构体是Engine，它作为单例存在；而Context是从对象池中得到。
// Context作为一个数据结构在中间件中传递本次请求的各种数据、管理流程，进行响应 // context.go:40 type Context struct { // ServeHTTP的第二个参数: request Request *http.Request // 用来响应 Writer ResponseWriter writermem responseWriter // URL里面的参数，比如：/xx/:id Params Params // 参与的处理者（中间件 + 请求处理者列表） handlers HandlersChain // 当前处理到的handler的下标 index int8 // Engine单例 engine *Engine // 在context可以设置的值 Keys map[string]interface{} // 一系列的错误 Errors errorMsgs // Accepted defines a list of manually accepted formats for content negotiation.</description>
    </item>
    
    <item>
      <title></title>
      <link>/SCA/docs/gin-gonic_gin/0200/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/SCA/docs/gin-gonic_gin/0200/</guid>
      <description>路由 #  本章讨论:
 路由调用逻辑：流程的流转逻辑 路由内部实现：基树：路由的内部实现  </description>
    </item>
    
    <item>
      <title></title>
      <link>/SCA/docs/gin-gonic_gin/0201_router/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/SCA/docs/gin-gonic_gin/0201_router/</guid>
      <description>路由调用逻辑
gin 对外宣传的高效，很大一部分是说其路由效率。本文内容包括：
 路由API介绍 路由调用实现逻辑 路由的内部实现  路由API #  设置路由 #  // routergroup.go:20 type IRoutes interface { Use(handlers ...HandlerFunc) IRoutes Handle(httpMethod, relativePath string, handlers ...HandlerFunc) IRoutes Any(relativePath string, handlers ...HandlerFunc) IRoutes GET(relativePath string, handlers ...HandlerFunc) IRoutes POST(relativePath string, handlers ...HandlerFunc) IRoutes DELETE(relativePath string, handlers ...HandlerFunc) IRoutes PATCH(relativePath string, handlers ...HandlerFunc) IRoutes PUT(relativePath string, handlers ...HandlerFunc) IRoutes OPTIONS(relativePath string, handlers ...HandlerFunc) IRoutes HEAD(relativePath string, handlers ...HandlerFunc) IRoutes StaticFile(relativePath, filepath string) IRoutes Static(relativePath, root string) IRoutes StaticFS(relativePath string, fs http.</description>
    </item>
    
    <item>
      <title></title>
      <link>/SCA/docs/gin-gonic_gin/0202_radix_tree/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/SCA/docs/gin-gonic_gin/0202_radix_tree/</guid>
      <description>路由内部实现：基树 #  路由的内部实现 #  前面我们把route接口层面的调用都过了一遍，gin的代码调用还是很简单直接的。
 程序 = 数据结构 + 算法
 gin的核心结构体叫 Engine ，那引擎到底在哪呢？我想就是它的路由实现。接下来我们去一窥究竟。
基树 #  基树维基百科 详细介绍了基树这种数据结构。它是gin的router的底层数据结构。
具体实现 #  node的数据结构： // tree.go:88 type node struct { // 相对路径 path string // 索引 indices string // 子节点 children []*node // 处理者列表 handlers HandlersChain priority uint32 // 结点类型：static, root, param, catchAll nType nodeType // 最多的参数个数 maxParams uint8 // 是否是通配符(:param_name | *param_name) wildChild bool } 基树的构建 #  构建的过程其实是不断寻找最长前缀的过程。</description>
    </item>
    
    <item>
      <title></title>
      <link>/SCA/docs/gin-gonic_gin/0301_request/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/SCA/docs/gin-gonic_gin/0301_request/</guid>
      <description>请求 #  其实在流程 中就有讲到。
在请求来到服务器后，Context对象会生成用来串流程： 和请求有关的字段包括:
// context.go:40 type Context struct { // ServeHTTP的第二个参数: request Request *http.Request // URL里面的参数，比如：/xx/:id Params Params } 获取restful接口的参数 #  在路由解析时会初始化 Params 提供Get函数：
Param(key string) string 获取请求数据： #  // Header GetHeader(key string) string // c.Request.Body GetRawData() ([]byte, error) // Cookie Cookie(name string) (string, error) //从GET参数中拿值，比如 /path?id=john // 实现原理：调用系统库：*http.Request.URL.Query() GetQueryArray(key string) ([]string, bool) GetQuery(key string)(string, bool) Query(key string) string DefaultQuery(key, defaultValue string) string GetQueryArray(key string) ([]string, bool) QueryArray(key string) []string //从POST中拿数据 // 实现原理：调用系统库：*http.</description>
    </item>
    
    <item>
      <title></title>
      <link>/SCA/docs/gin-gonic_gin/0401_response/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/SCA/docs/gin-gonic_gin/0401_response/</guid>
      <description>响应 #  其实在流程 中就有讲到。
在请求来到服务器后，Context对象会生成用来串流程： 和请求有关的字段包括:
// context.go:40 type Context struct { // 用来响应 Writer ResponseWriter writermem responseWriter } // response_writer.go:20 type ResponseWriter interface { http.ResponseWriter //嵌入接口 http.Hijacker //嵌入接口 http.Flusher //嵌入接口 http.CloseNotifier //嵌入接口 // 返回当前请求的 response status code Status() int // 返回写入 http body的字节数 Size() int // 写string WriteString(string) (int, error) //是否写出 Written() bool // 强制写htp header (状态码 + headers) WriteHeaderNow() } // response_writer.go:40 // 实现 ResponseWriter 接口 type responseWriter struct { http.</description>
    </item>
    
    <item>
      <title></title>
      <link>/SCA/docs/gin-gonic_gin/0501_other/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/SCA/docs/gin-gonic_gin/0501_other/</guid>
      <description>其他主题 #  基本上介绍完 gin 框架了，一个非常克制的框架，提供了路由、使用 Context 来封装数据。 golang的原生库对web开发是较为完善的，所有的框架只能是工具集。
中间件 #  中间件实际上上特殊的 HandleFuc 注册在 Engine.RouterGroup 上，最终会附加到每个节点的handlerList前，每次处理时依次调用。
gin 提供了几个中间件:
 auth: auth.go，完成基本的鉴权 log: logger.go，完成请求日志输出 recover: recover.go， 完成崩溃处理  错误管理 #  错误管理是指在业务处理中可以将错误不断的设置到context中，然后可以一次性处理，比如记日志。
// context.go:40 type Context struct { // 一系列的错误 Errors errorMsgs } Error(err error) *Error // 给本次请求添加个错误。将错误收集然后用中间件统一处理（打日志|入库）是一个比较好的方案 元数据管理 #  // context.go:40 type Context struct { // 在context可以设置的值 Keys map[string]interface{} } Set(key string, value interface{}) //本次请求用户设置各种数据 (Keys 字段) Get(key string)(value interface{}, existed bool) MustGet(key string)(value interface{}) GetString(key string) string GetBool(key string) bool GetInt(key string) int GetInt64(key string) int64 GetFloat64(key string) float64 GetTime(key string) time.</description>
    </item>
    
    <item>
      <title></title>
      <link>/SCA/docs/tal-tech_go-zero/core/01_bloom_filter/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/SCA/docs/tal-tech_go-zero/core/01_bloom_filter/</guid>
      <description>布隆过滤器 #  包 core/bloom 提供了一个布隆过滤器的实现。
什么是 布隆过滤器？ #  布隆过滤器是 burton Bloom 在 1970年提出来的一个 用来处理 元素是否在集合中的 方法。对于海量数据，使用布隆过滤器在判定某个元素是否在其中时具有极高的空间效率和查询效率。它不会漏判，但是可能误判（不在里面的被认为在里面）。
布隆过滤器基本原理 #  布隆过滤器由一个超大的位数组A和M个hash函数组成，它支持两种操作：
 添加元素K：  将K依次交给M个函数运算，得到M个下标，将A中下标的值都设置为1   查询元素K：  将K依次交给M个函数运算，得到M个下标，如果A中这些下标的值都是1，则代表元素（可能）存在，不然就是（一定）不存在    不支持删除。
布隆过滤器的误差率 #  有专门的分析。
布隆过滤器的应用 #   判断某个邮箱地址在不在上亿个邮箱地址中 判断某个URL爬虫是否扒取过 判断某个数据在数据库是否存在 &amp;hellip;  go-zero布隆过滤器的实现 #  go-zero 中使用redis来存储位数组，自定义了hash函数。
hash 函数 #  // 根据 key 得到 M 个下标 func (f *BloomFilter) getLocations(data []byte) []uint { locations := make([]uint, maps) // maps = 14 	for i := uint(0); i &amp;lt; maps; i++ { // 每次将 i 追加到数据本身中，使用同一个hash函数得到不同的下标 	hashValue := hash.</description>
    </item>
    
    <item>
      <title></title>
      <link>/SCA/docs/tal-tech_go-zero/core/02_break/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/SCA/docs/tal-tech_go-zero/core/02_break/</guid>
      <description>熔断器 #  包 `core/break 提供了一个熔断器的接口和两套实现。
什么是 熔断器？ #  服务端经常会面临的一个问题是服务器负载过高，比如某个热点新闻导致流量短时间激增，这个时候如果不做相应的保护，服务端可能发生宕机导致直接不可用。处理这种情况一般会：
 服务降级：比如返回静态数据 服务熔断：对部分请求直接返回服务不可用，对其他请求继续提供服务  熔断器就是完成熔断功能的组件。它应该决定是否为当前请求提供正常服务，还是直接拒绝。
go-zero熔断器的实现 #  接口定义 #  type ( // 判断一个错误返回是否依旧是成功的 	Acceptable func(err error) bool Breaker interface { // Name returns the name of the netflixBreaker. 	Name() string // 判断请求是否被允许  // 如果允许，调用方需要在调用成功后调用 promise.Accept(),失败后调用 promise.Reject  // 如果不被允许（限流了），返回的是 ErrServiceUnavailable 	Allow() (Promise, error) // DoWithFallbackAcceptable  // - 在未被限流时执行req  // - 被限流时执行fallback（回退） 	// - acceptable 检查 req 是否调用成功，即便req返回的err不是nil 	DoWithFallbackAcceptable(req func() error, fallback func(err error) error, acceptable Acceptable) error // DoWithFallbackAcceptable 的简化版  // acceptable 为 err == nil 	DoWithFallback(req func() error, fallback func(err error) error) error // DoWithFallbackAcceptable 的简化版  // fallback 逻辑为：nil 不做回退 	DoWithAcceptable(req func() error, acceptable Acceptable) error // DoWithFallbackAcceptable 的简化版  // acceptable 为 err == nil  // fallback 逻辑为：nil 不做回退 	Do(req func() error) error } ) 可以看见，类库实现的Breaker里面本质上只有两个接口：</description>
    </item>
    
    <item>
      <title></title>
      <link>/SCA/docs/tal-tech_go-zero/core/03_collection/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/SCA/docs/tal-tech_go-zero/core/03_collection/</guid>
      <description>集合 #  包 core/collection 实现了各种典型集合类型
RollingWindow #  限流的方案在 熔断器 里面讲过，Rolling Window 就是一个经典的算法。
为了解决计算一段时间Interval的请求次数，滑动窗口算法的做法为：将计算周期切成N个Bucket，每个请求过来后，将请求放入对应的Bucket中，当要计算window有多少个请求时，把相关所有的bucket的数据累计起来即可。
我们先看看数据结构定义：
type RollingWindow struct { lock sync.RWMutex // 有多少个计数器 size int // 每个计算器的计数周期 interval time.Duration // 窗口，由多个Bucket组成 win *window // 窗口的偏移，范围为 [0, size) offset int // 最后一次更新的时间 lastTime time.Duration ignoreCurrent bool } type window struct { buckets []*Bucket // 一个window有多个Bucket size int } type Bucket struct { Sum float64 Count int64 } 我们再看看行为定义：
// 添加个数 func (rw *RollingWindow) Add(v float64) // 通过这个函数拿到当前的状态 // 会找到多个Bucket，需要总数的话直接累加即可 func (rw *RollingWindow) Reduce(fn func(b *Bucket)) 其实算法也不是那么的高深，一个滑动窗口由多个bucket组成：</description>
    </item>
    
    <item>
      <title></title>
      <link>/SCA/docs/tal-tech_go-zero/core/04_executor/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/SCA/docs/tal-tech_go-zero/core/04_executor/</guid>
      <description>执行器 #  包 core/executors 实现了各种类型的执行器。
   执行器类型 执行器使用场景     PeriodicalExecutor 每隔一段时间执行一次   BulkExecutor 凑够多个执行一次   ChunkExecutor 凑够多个字节执行一次   DelayExecutor 延迟一段时间后执行   LessExecutor 一段时间内最多执行一次    满足条件周期触发 #  PeriodicalExecutor 是任务在时间上的聚集，BulkExecutor 是时间+任务数， ChunkExecutor 是 时间+字节数。它们都是任务在一定条件下的触发。
类库在实现时，提出了一个任务容器的接口，来描述触发条件和任务的执行方式：
type TaskContainer interface { // 添加任务，返回是否需要执行任务了  // 对于 BulkExecutor，就是任务数量到了 	AddTask(task interface{}) bool // 执行任务 	Execute(tasks interface{}) // 移除所有任务，并返回它们 	RemoveAll() interface{} } 作为BulkExecutor和ChunkExecutor的基础，PeriodicalExecutor的接口如下：</description>
    </item>
    
    <item>
      <title></title>
      <link>/SCA/docs/tal-tech_go-zero/core/05_fx/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/SCA/docs/tal-tech_go-zero/core/05_fx/</guid>
      <description>执行器 #  包 core/fx 实现了流式运算的API。
Java里面有流式运算相关的API。Stream 就如同一个迭代器（Iterator），单向，不可往复，数据只能遍历一次，遍历过一次后即用尽了，就好比流水从面前流过，一去不复返。而和迭代器又不同的是，Stream 可以并行化操作，迭代器只能命令式地、串行化操作。顾名思义，当使用串行方式去遍历时，每个 item 读完后再读下一个 item。而使用并行去遍历时，数据会被分成多个段，其中每一个都在不同的线程中处理，然后将结果一起输出。
Stream的数据结构 #  Stream只有一个数据成员：
type Stream struct { // 所有的数据都在chan里面 	source &amp;lt;-chan interface{} } Stream的工厂方法 #  创建流对象本质是是把多个同类型的元素放入chan中，类库提供了如下的工厂方法：
type GenerateFunc func(source chan&amp;lt;- interface{}) func From(generate GenerateFunc) Stream func Just(items ...interface{}) Stream func Range(source &amp;lt;-chan interface{}) Stream Stream的API #  对于Stream，有如下API：
 元素处理API  // 将n个数据放入新的Stream中 func (p Stream) Buffer(n int) Stream // 取 Top N func (p Stream) Head(n int64) Stream // 取 Head N func (p Stream) Tail(n int64) Stream // 排序元素 func (p Stream) Sort(less LessFunc) Stream // 反转元素 func (p Stream) Reverse() Stream // 将元素分组，Stream的chan里面每个元素为一组原始的元素 func (p Stream) Group(fn KeyFunc) Stream // 将元素分组，Stream的chan里面只有一个元素，为原始的所有的元素 func (p Stream) Merge() Stream // 过滤元素 func (p Stream) Filter(fn FilterFunc, opts .</description>
    </item>
    
    <item>
      <title></title>
      <link>/SCA/docs/tal-tech_go-zero/core/06_hash/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/SCA/docs/tal-tech_go-zero/core/06_hash/</guid>
      <description>一致性hash #  状态：编辑中
包 core/hash 实现了一个一致性hash。
hash 和 一致性hash #  hash函数将一个字符串（字节数组）转换为一个数值，比如md5。
在业务开发中，经常会使用hash函数将数据打散到多个存储实例上，比如：
 数据库水平分表：hash(用户的名字) 后和总表数取模确定存储在哪张表中 缓存集群挑选：hask(key) 后和 缓存集群格式取模确定数据缓存在哪个缓存集群中  realAddr = hash(key) % node_count 这种方式，在instance_count 不变的情况下是工作良好的，但是真实的生产环境却是动态的，就会有如下问题：
 容错性：实例宕机了，某个实例下线后，最坏情况（第一个实例下线）会导致所有的数据都失效，最好情况（最后一个实例下线）是 1/n 的数据失效 扩展性：添加新实例同上  一致性hash就是用来解决这个问题的。
普通的算法是将N个物理节点组成一个环，通过和N取模确定到底使用哪个具体的节点，每个节点对应一个物理节点
一致性hash先得到一个有N个虚拟节点的环，我们先认为N = 2^32 - 1。
 将每个机器节点hash后与N取模能够得到机器在虚拟环的位置P 通过Key和N取模确定是哪个虚拟节点n 顺着虚拟环顺时针查找到的第一个P就是需要使用的物理节点  我们来分析一下一致性hash的表现：
 容错性：实例宕机了，某个实例下线后，总是 1/n 的数据失效 扩展性：添加新实例，总是少于 1/n的数据受影响  有一个地方需要特别注意一下： 将每个机器节点hash后与N取模能够得到机器在虚拟环的位置P 这步，如果做得不够均匀，就会导致 数据倾斜，也就是每个物理节点的负载不一样。
比如有N物理节点，它们的P 相减为 2^32 / N 才比较对，极端情况P相差1，那么就有一台物理节点几乎承担所有的负载。
解决这个问题的一种方法为对每个物理节点进行多个hash，每次计算的结果为一个虚拟节点。同一个物理节点的多个虚拟节点都是该物理节点服务的范围。通过多个hash，降低数据倾斜的概率。
一致性hash的API #  type ( HashFunc func(data []byte) uint64 ConsistentHash struct { // 将key转换为int的函数 	hashFunc HashFunc // 副本的数量，也就是上面虚拟节点的数量 	replicas int // 	keys []uint64 // 	ring map[uint64][]interface{} // 用来确认某个节点是否存在的冗余数据 	nodes map[string]lang.</description>
    </item>
    
    <item>
      <title></title>
      <link>/SCA/docs/tal-tech_go-zero/core/09_other/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/SCA/docs/tal-tech_go-zero/core/09_other/</guid>
      <description>其他 #     包 说明     cmdline 命令行接收相关的工具函数   codec 加解密/编码相关的二次封装   conf yaml/json加解密, kv 的序列化和反序列化   contextx context 的二次封装   errorx error相关的二次封装，包括多个error和原子化操作的error   filex 文件相关的封装，比如读取文件第一行/最后一行    </description>
    </item>
    
  </channel>
</rss>
